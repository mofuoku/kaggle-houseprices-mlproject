{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import the following packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the right libraries \n",
    "# load the libraries needed to run the analysis\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import re\n",
    "import scipy\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "# Training data\n",
    "house = pd.read_csv('/Users/mofuoku/Desktop/train.csv')\n",
    "\n",
    "# Test data \n",
    "house_test = pd.read_csv('/Users/mofuoku/Desktop/test.csv')\n",
    "\n",
    "trainSize = house.shape[0]\n",
    "house.SalePrice = house.SalePrice.apply(np.log)\n",
    "print(house.shape)\n",
    "print(house_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                count          mean          std          min          25%  \\\n",
      "Id             1460.0    730.500000   421.610009     1.000000   365.750000   \n",
      "MSSubClass     1460.0     56.897260    42.300571    20.000000    20.000000   \n",
      "LotFrontage    1201.0     70.049958    24.284752    21.000000    59.000000   \n",
      "LotArea        1460.0  10516.828082  9981.264932  1300.000000  7553.500000   \n",
      "OverallQual    1460.0      6.099315     1.382997     1.000000     5.000000   \n",
      "OverallCond    1460.0      5.575342     1.112799     1.000000     5.000000   \n",
      "YearBuilt      1460.0   1971.267808    30.202904  1872.000000  1954.000000   \n",
      "YearRemodAdd   1460.0   1984.865753    20.645407  1950.000000  1967.000000   \n",
      "MasVnrArea     1452.0    103.685262   181.066207     0.000000     0.000000   \n",
      "BsmtFinSF1     1460.0    443.639726   456.098091     0.000000     0.000000   \n",
      "BsmtFinSF2     1460.0     46.549315   161.319273     0.000000     0.000000   \n",
      "BsmtUnfSF      1460.0    567.240411   441.866955     0.000000   223.000000   \n",
      "TotalBsmtSF    1460.0   1057.429452   438.705324     0.000000   795.750000   \n",
      "1stFlrSF       1460.0   1162.626712   386.587738   334.000000   882.000000   \n",
      "2ndFlrSF       1460.0    346.992466   436.528436     0.000000     0.000000   \n",
      "LowQualFinSF   1460.0      5.844521    48.623081     0.000000     0.000000   \n",
      "GrLivArea      1460.0   1515.463699   525.480383   334.000000  1129.500000   \n",
      "BsmtFullBath   1460.0      0.425342     0.518911     0.000000     0.000000   \n",
      "BsmtHalfBath   1460.0      0.057534     0.238753     0.000000     0.000000   \n",
      "FullBath       1460.0      1.565068     0.550916     0.000000     1.000000   \n",
      "HalfBath       1460.0      0.382877     0.502885     0.000000     0.000000   \n",
      "BedroomAbvGr   1460.0      2.866438     0.815778     0.000000     2.000000   \n",
      "KitchenAbvGr   1460.0      1.046575     0.220338     0.000000     1.000000   \n",
      "TotRmsAbvGrd   1460.0      6.517808     1.625393     2.000000     5.000000   \n",
      "Fireplaces     1460.0      0.613014     0.644666     0.000000     0.000000   \n",
      "GarageYrBlt    1379.0   1978.506164    24.689725  1900.000000  1961.000000   \n",
      "GarageCars     1460.0      1.767123     0.747315     0.000000     1.000000   \n",
      "GarageArea     1460.0    472.980137   213.804841     0.000000   334.500000   \n",
      "WoodDeckSF     1460.0     94.244521   125.338794     0.000000     0.000000   \n",
      "OpenPorchSF    1460.0     46.660274    66.256028     0.000000     0.000000   \n",
      "EnclosedPorch  1460.0     21.954110    61.119149     0.000000     0.000000   \n",
      "3SsnPorch      1460.0      3.409589    29.317331     0.000000     0.000000   \n",
      "ScreenPorch    1460.0     15.060959    55.757415     0.000000     0.000000   \n",
      "PoolArea       1460.0      2.758904    40.177307     0.000000     0.000000   \n",
      "MiscVal        1460.0     43.489041   496.123024     0.000000     0.000000   \n",
      "MoSold         1460.0      6.321918     2.703626     1.000000     5.000000   \n",
      "YrSold         1460.0   2007.815753     1.328095  2006.000000  2007.000000   \n",
      "SalePrice      1460.0     12.024051     0.399452    10.460242    11.775097   \n",
      "\n",
      "                       50%           75%            max  \n",
      "Id              730.500000   1095.250000    1460.000000  \n",
      "MSSubClass       50.000000     70.000000     190.000000  \n",
      "LotFrontage      69.000000     80.000000     313.000000  \n",
      "LotArea        9478.500000  11601.500000  215245.000000  \n",
      "OverallQual       6.000000      7.000000      10.000000  \n",
      "OverallCond       5.000000      6.000000       9.000000  \n",
      "YearBuilt      1973.000000   2000.000000    2010.000000  \n",
      "YearRemodAdd   1994.000000   2004.000000    2010.000000  \n",
      "MasVnrArea        0.000000    166.000000    1600.000000  \n",
      "BsmtFinSF1      383.500000    712.250000    5644.000000  \n",
      "BsmtFinSF2        0.000000      0.000000    1474.000000  \n",
      "BsmtUnfSF       477.500000    808.000000    2336.000000  \n",
      "TotalBsmtSF     991.500000   1298.250000    6110.000000  \n",
      "1stFlrSF       1087.000000   1391.250000    4692.000000  \n",
      "2ndFlrSF          0.000000    728.000000    2065.000000  \n",
      "LowQualFinSF      0.000000      0.000000     572.000000  \n",
      "GrLivArea      1464.000000   1776.750000    5642.000000  \n",
      "BsmtFullBath      0.000000      1.000000       3.000000  \n",
      "BsmtHalfBath      0.000000      0.000000       2.000000  \n",
      "FullBath          2.000000      2.000000       3.000000  \n",
      "HalfBath          0.000000      1.000000       2.000000  \n",
      "BedroomAbvGr      3.000000      3.000000       8.000000  \n",
      "KitchenAbvGr      1.000000      1.000000       3.000000  \n",
      "TotRmsAbvGrd      6.000000      7.000000      14.000000  \n",
      "Fireplaces        1.000000      1.000000       3.000000  \n",
      "GarageYrBlt    1980.000000   2002.000000    2010.000000  \n",
      "GarageCars        2.000000      2.000000       4.000000  \n",
      "GarageArea      480.000000    576.000000    1418.000000  \n",
      "WoodDeckSF        0.000000    168.000000     857.000000  \n",
      "OpenPorchSF      25.000000     68.000000     547.000000  \n",
      "EnclosedPorch     0.000000      0.000000     552.000000  \n",
      "3SsnPorch         0.000000      0.000000     508.000000  \n",
      "ScreenPorch       0.000000      0.000000     480.000000  \n",
      "PoolArea          0.000000      0.000000     738.000000  \n",
      "MiscVal           0.000000      0.000000   15500.000000  \n",
      "MoSold            6.000000      8.000000      12.000000  \n",
      "YrSold         2008.000000   2009.000000    2010.000000  \n",
      "SalePrice        12.001505     12.273731      13.534473  \n"
     ]
    }
   ],
   "source": [
    "#Transpose the results to make printing on the screen easier.\n",
    "summary = house.describe()\n",
    "summary = summary.transpose()\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some details about the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Understanding Data \n",
    "#df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the Id column:\n",
    "train_id = house['Id']\n",
    "test_id  = house_test['Id']\n",
    "\n",
    "# Now drop the 'Id' column \n",
    "# since we can not use it as a feature to train our model.\n",
    "house.drop(\"Id\", axis = 1, inplace = True)\n",
    "house_test.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinguish the NA and missing in train data\n",
    "miss = list(house.columns[house.isnull().sum(axis = 0) >= 1])\n",
    "miss.remove('LotFrontage')\n",
    "miss.remove('MasVnrArea')\n",
    "miss.remove('GarageYrBlt')\n",
    "miss.remove('MasVnrType')\n",
    "\n",
    "house.loc[house['MasVnrType'].isnull() == True, 'MasVnrType'] = 'None'\n",
    "house.loc[house['Electrical'].isnull() == True, 'Electrical'] = 'SBrkr'\n",
    "\n",
    "for i in range(len(miss)):\n",
    "    house.loc[house[miss[i]].isnull() == True, miss[i]] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/Users/mofuoku/Desktop/data_description.txt', 'r') as file:\n",
    "    lines_level = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ''\n",
    "levels = {}\n",
    "level = ''\n",
    "\n",
    "for line in lines_level:\n",
    "    if (not not re.findall(': ', line)) and (not re.findall('story:', line)):\n",
    "#         features.append(re.split(':', line)[0])\n",
    "        feature = re.split(':', line)[0]\n",
    "        levels[feature] = []\n",
    "    else:\n",
    "        if line != '\\n':\n",
    "#             levels.append(re.split('\\t', line)[0].strip())\n",
    "            level = re.split('\\t', line)[0].strip()\n",
    "            if level != '': levels[feature].append(level)\n",
    "levels['Id'] = []\n",
    "levels['SalePrice'] = []\n",
    "# print(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ordinal and non ordinal\n",
    "with open('/Users/mofuoku/Desktop/DataDocumentation.txt', 'r',encoding='cp1252') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1', 'Exterior2', 'MasVnrType', 'Foundation', 'Heating', 'CentralAir', 'GarageType', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "['LotShape', 'Utilities', 'LandSlope', 'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence']\n"
     ]
    }
   ],
   "source": [
    "# Convert string data to numerical data \n",
    "\n",
    "nom_lines = []\n",
    "ord_lines = []\n",
    "for line in lines:\n",
    "    if re.findall('(Nominal)', line):\n",
    "        nom_lines.append(re.sub(' ', '', re.split('\\(Nominal\\)', line)[0].strip()))\n",
    "    elif re.findall('(Ordinal)', line):\n",
    "        ord_lines.append(re.sub(' ', '', re.split('\\(Ordinal\\)', line)[0].strip()))\n",
    "print(nom_lines)\n",
    "print(ord_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cat(col, levels, ord_lines):\n",
    "    if not not levels[col.name]: \n",
    "        if col.name in ord_lines:\n",
    "            temp = pd.Categorical(list(col.astype('str')), ordered=True, categories=levels[col.name][::-1])\n",
    "            temp.name = col.name\n",
    "            return temp\n",
    "        else:\n",
    "            temp = pd.Categorical(list(col.astype('str')), categories=levels[col.name][::-1])\n",
    "            temp.name = col.name\n",
    "            return temp\n",
    "   \n",
    "    else:\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in house:\n",
    "    house[col] = my_cat(house[col], levels, ord_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = list(house_test.columns[house_test.isnull().sum(axis = 0) >= 1])\n",
    "miss.remove('LotFrontage')\n",
    "miss.remove('MasVnrArea')\n",
    "miss.remove('GarageYrBlt')\n",
    "miss.remove('TotalBsmtSF')\n",
    "miss.remove('BsmtHalfBath')\n",
    "miss.remove('BsmtFullBath')\n",
    "miss.remove('GarageCars')\n",
    "miss.remove('GarageArea')\n",
    "miss.remove('BsmtFinSF1')\n",
    "miss.remove('BsmtFinSF2')\n",
    "miss.remove('BsmtUnfSF')\n",
    "\n",
    "house_test.loc[house_test['MasVnrType'].isnull() == True, 'MasVnrType'] = 'CBlock'\n",
    "house_test.loc[house_test['SaleType'].isnull() == True, 'SaleType'] = 'Oth'\n",
    "house_test.loc[house_test['Functional'].isnull() == True, 'Functional'] = 'Sal'\n",
    "house_test.loc[house_test['MSZoning'].isnull() == True, 'MSZoning'] = 'A'\n",
    "house_test.loc[house_test['Exterior1st'].isnull() == True, 'Exterior1st'] = 'WdShing'\n",
    "house_test.loc[house_test['Exterior2nd'].isnull() == True, 'Exterior2nd'] = 'Wd Shng'\n",
    "\n",
    "for i in range(len(miss)):\n",
    "    house_test.loc[house_test[miss[i]].isnull() == True, miss[i]] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in house_test:\n",
    "    house_test[col] = my_cat(house_test[col], levels, ord_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['NA', 'Unf', 'RFn', 'Fin']\n",
      "['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['Po', 'Fa', 'TA', 'Gd', 'Ex']\n"
     ]
    }
   ],
   "source": [
    "print(levels['OverallQual'][::-1])\n",
    "print(levels['ExterQual'][::-1])\n",
    "print(levels['BsmtQual'][::-1])\n",
    "print(levels['KitchenQual'][::-1])\n",
    "print(levels['GarageFinish'][::-1])\n",
    "print(levels['FireplaceQu'][::-1])\n",
    "print(levels['HeatingQC'][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OrdinalsToNumerics(all_data):    \n",
    "    all_data['ExterQual'] = all_data['ExterQual'].map(lambda x: {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}.get(x, 0))\n",
    "    all_data['BsmtQual'] = all_data['BsmtQual'].map(lambda x: {'NA':1,'Po':2, 'Fa':3, 'TA':4, 'Gd':5, 'Ex':6}.get(x, 0))\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].map(lambda x: {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}.get(x, 0))\n",
    "    all_data['GarageFinish'] = all_data['GarageFinish'].map(lambda x: {'NA':1, 'Unf':2, 'RFn':3, 'Fin':4}.get(x, 0))\n",
    "    all_data['FireplaceQu'] = all_data['FireplaceQu'].map(lambda x: {'NA':1,'Po':2, 'Fa':3, 'TA':4, 'Gd':5, 'Ex':6}.get(x, 0))\n",
    "    all_data['HeatingQC'] = all_data['HeatingQC'].map(lambda x: {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}.get(x, 0))\n",
    "\n",
    "    all_data['OverallQual'] = pd.to_numeric(all_data['OverallQual'])\n",
    "    all_data['ExterQual'] = pd.to_numeric(all_data['ExterQual'])\n",
    "    all_data['BsmtQual'] = pd.to_numeric(all_data['BsmtQual'])\n",
    "    all_data['KitchenQual'] = pd.to_numeric(all_data['KitchenQual'])\n",
    "    all_data['GarageFinish'] = pd.to_numeric(all_data['GarageFinish'])\n",
    "    all_data['FireplaceQu'] = pd.to_numeric(all_data['FireplaceQu'])\n",
    "    all_data['HeatingQC'] = pd.to_numeric(all_data['HeatingQC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea taken from this script: https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "# # Add some family features directly to new columns in the dataset\n",
    "\n",
    "def FeatureEngineering(all_data):\n",
    "    # Adding total sqfootage feature \n",
    "    all_data['GarageYrBlt'][all_data['GarageYrBlt'].isnull()] = all_data['YearBuilt'][all_data['GarageYrBlt'].isnull()]\n",
    "    all_data['GarageYrBlt'] = all_data['GarageYrBlt'] - all_data['YearBuilt']\n",
    "\n",
    "    #all_data['YrSold'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "    \n",
    "    all_data['MoSold'] = pd.Categorical(list(all_data['MoSold'].astype('str')))\n",
    "    \n",
    "    all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "\n",
    "    # GarageYrBlt, GarageArea and GarageCars : Replacing missing data with 0 (Since No garage = no cars in such garage.)\n",
    "    for col in ('GarageArea', 'GarageCars'):\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "    # BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath and BsmtHalfBath : missing values are likely zero for having no basement\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "    # LotFrontage : Since the area of each street connected to the house property most likely have a similar \n",
    "    # area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood.\n",
    "    # Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "    all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "    \n",
    "    # Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.\n",
    "    all_data = all_data.drop(['Utilities'], axis=1)\n",
    "\n",
    "drop_cols1 = [\"Alley\", \"ExterCond\", \"BsmtFinSF2\", \"Heating\", \"Electrical\",\\\n",
    "              \"BsmtHalfBath\", \"PavedDrive\", \"Fence\", \"MiscFeature\", \"MoSold\"]\n",
    "\n",
    "drop_cols2 = [\"BsmtFinType2\", \"LandContour\", \"EnclosedPorch\",\\\n",
    "              \"SaleType\", \"Functional\", \"LotConfig\",\\\n",
    "              \"ScreenPorch\", \"YrSold\", \"LandSlope\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify columns to drop\n",
    "def DropColumns(all_data):\n",
    "    for col in [*drop_cols1, *drop_cols2]:\n",
    "        all_data.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = house.SalePrice\n",
    "house.drop('SalePrice', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "OrdinalsToNumerics(house)\n",
    "OrdinalsToNumerics(house_test)\n",
    "\n",
    "FeatureEngineering(house)\n",
    "FeatureEngineering(house_test)\n",
    "\n",
    "DropColumns(house)\n",
    "DropColumns(house_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([house, house_test], ignore_index = True)\n",
    "all_data = pd.get_dummies(all_data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 219)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = all_data.iloc[:trainSize,:]\n",
    "train_clean = train_clean.assign(SalePrice = price.values)\n",
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 218)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean = all_data.iloc[trainSize:, :]\n",
    "test_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "\n",
    "# The usual\n",
    "import numpy as np\n",
    "\n",
    "# sklearn tools for model training and assesment\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split,KFold\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor #as gbr as rfr\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "# LightGBM\n",
    "import lightgbm as lgb\n",
    "# Lightxgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split the dataset into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_const = 80 #always use the same one value for all model tuning process\n",
    "test_ratio_const = 0.2 \n",
    "\n",
    "train_data   = train_clean.drop('SalePrice', axis=1)\n",
    "train_target = train_clean[['SalePrice']]\n",
    "test_data    = test_clean\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target,\\\n",
    "                                                    test_size=test_ratio_const, random_state=rs_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape =  (1168, 218)\n",
      "X test shape =  (292, 218)\n",
      "Y train shape =  (1168, 1)\n",
      "Y test shape =  (292, 1)\n"
     ]
    }
   ],
   "source": [
    "print('X train shape = ',X_train.shape)\n",
    "print('X test shape = ', X_test.shape)\n",
    "print('Y train shape = ', y_train.shape)\n",
    "print('Y test shape = ',y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter space\n",
    "C = np.logspace(0, 4, 10)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create grid search using 5-fold cross validation\n",
    "clf = GridSearchCV(logistic, hyperparameters, cv=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View Hyperparameter Values Of Best Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View best hyperparameters\n",
    "print('Best Penalty:', best_model.best_estimator_.get_params()['penalty'])\n",
    "print('Best C:', best_model.best_estimator_.get_params()['C'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train: 0.10262489450225752\n",
      "RMSE test : 0.1273096943564471\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE train: {}\".format(rmse(y_train, model_lr.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Kernel Ridge Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_krr = [{'alpha': np.logspace(-4, 4, 20)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_krr = GridSearchCV(estimator=linear_model.Ridge(random_state=rs_const),param_grid= param_grid_krr, n_jobs=-1,cv=5, verbose=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   18.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=80, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'alpha': array([1.00000e-04, 2.63665e-04, 6.95193e-04, 1.83298e-03, 4.83293e-03,\n",
       "       1.27427e-02, 3.35982e-02, 8.85867e-02, 2.33572e-01, 6.15848e-01,\n",
       "       1.62378e+00, 4.28133e+00, 1.12884e+01, 2.97635e+01, 7.84760e+01,\n",
       "       2.06914e+02, 5.45559e+02, 1.43845e+03, 3.79269e+03, 1.00000e+04])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_krr.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Evaluating the model and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "krr: Regression\n",
      "_______________________________________\n",
      "Best params: {'alpha': 545.5594781168514}\n",
      "Best score : 0.862816990220294\n",
      "---------\n",
      "RMSE train: 0.11500081056347171\n",
      "RMSE test : 0.09967169272824544\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________\")\n",
    "print(\"krr: Regression\")\n",
    "print(\"_______________________________________\")\n",
    "print('Best params: {}'.format(gridsearch_krr.best_params_))\n",
    "print('Best score : {}'.format(gridsearch_krr.best_score_))\n",
    "print(\"---------\")\n",
    "model_krr = gridsearch_krr.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_krr.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_krr.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lasso = [{'alpha': np.logspace(-3, 4, 20)}] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_lasso = GridSearchCV(estimator=linear_model.Lasso(random_state=rs_const, normalize=False), param_grid=param_grid_lasso, n_jobs=-1,cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  44 tasks      | elapsed:   19.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   19.5s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=80,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'alpha': array([1.00000e-03, 2.33572e-03, 5.45559e-03, 1.27427e-02, 2.97635e-02,\n",
       "       6.95193e-02, 1.62378e-01, 3.79269e-01, 8.85867e-01, 2.06914e+00,\n",
       "       4.83293e+00, 1.12884e+01, 2.63665e+01, 6.15848e+01, 1.43845e+02,\n",
       "       3.35982e+02, 7.84760e+02, 1.83298e+03, 4.28133e+03, 1.00000e+04])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_lasso.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate The Model And Print The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "Lasso: Regression\n",
      "_______________________________________\n",
      "Best params: {'alpha': 0.00545559478116852}\n",
      "Best score : 0.8564711534949876\n",
      "---------\n",
      "RMSE train: 0.11500081056347171\n",
      "RMSE test : 0.09967169272824544\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________\")\n",
    "print(\"Lasso: Regression\")\n",
    "print(\"_______________________________________\")\n",
    "print('Best params: {}'.format(gridsearch_lasso.best_params_))\n",
    "print('Best score : {}'.format(gridsearch_lasso.best_score_))\n",
    "print(\"---------\")\n",
    "model_lasso = gridsearch_krr.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_lasso.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_lasso.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_enet = [{'alpha': np.logspace(-2, 4, 20), 'l1_ratio': np.linspace(0.015, 1, 20)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_enet = GridSearchCV(estimator=linear_model.ElasticNet(random_state=rs_const), param_grid=param_grid_enet, n_jobs=-1,cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 400 candidates, totalling 2000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 478 tasks      | elapsed:    7.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1478 tasks      | elapsed:   15.6s\n",
      "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:   19.2s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=80, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid=[{'alpha': array([1.00000e-02, 2.06914e-02, 4.28133e-02, 8.85867e-02, 1.83298e-01,\n",
       "       3.79269e-01, 7.84760e-01, 1.62378e+00, 3.35982e+00, 6.95193e+00,\n",
       "       1.43845e+01, 2.97635e+01, 6.15848e+01, 1.27427e+02, 2.63665e+02,\n",
       "       5.45559e+02, 1.12884e+03, 2.33572e+03, 4.83293e+03, 1.0... 0.53342, 0.58526, 0.63711, 0.68895,\n",
       "       0.74079, 0.79263, 0.84447, 0.89632, 0.94816, 1.     ])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_enet.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate The Model And Print The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.18329807108324356, 'l1_ratio': 0.015}\n",
      "Best score : 0.8652189389746141\n",
      "RMSE train: 0.1127655445071562\n",
      "RMSE test : 0.0955844475998484\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(gridsearch_enet.best_params_))\n",
    "print('Best score : {}'.format(gridsearch_enet.best_score_))\n",
    "\n",
    "model_en = gridsearch_enet.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_en.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_en.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_gboost = {\n",
    "                    'learning_rate' : [0.005, 0.01,0.05],\n",
    "                    'n_estimators': [2000,3000,4000],\n",
    "                    'max_depth' : [4,5,7],\n",
    "                    'min_samples_split': [5,7,9], \n",
    "                    'min_samples_leaf' : [1,3,5],\n",
    "                     'max_features' : ['sqrt'],\n",
    "                    'subsample':[0.7,0.8,0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_gboost= GridSearchCV(estimator=GradientBoostingRegressor(random_state=rs_const), param_grid=param_grid_gboost,n_jobs=-1, cv=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  1.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 13.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 25.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 46.8min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 64.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 92.4min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 117.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3645 out of 3645 | elapsed: 134.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_sampl...te=80, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.005, 0.01, 0.05], 'n_estimators': [2000, 3000, 4000], 'max_depth': [4, 5, 7], 'min_samples_split': [5, 7, 9], 'min_samples_leaf': [1, 3, 5], 'max_features': ['sqrt'], 'subsample': [0.7, 0.8, 0.9]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_gboost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate The Model And Print The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "gboost: Regression\n",
      "_______________________________________\n",
      "Best params: {'learning_rate': 0.005, 'max_depth': 4, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 4000, 'subsample': 0.7}\n",
      "Best score : 0.9037900540991681\n",
      "---------\n",
      "RMSE train: 0.05638277444860054\n",
      "RMSE test : 0.09656160461178102\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________\")\n",
    "print(\"gboost: Regression\")\n",
    "print(\"_______________________________________\")\n",
    "print('Best params: {}'.format(gridsearch_gboost.best_params_))\n",
    "print('Best score : {}'.format(gridsearch_gboost.best_score_))\n",
    "print(\"---------\")\n",
    "model_gboost = gridsearch_gboost.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_gboost.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_gboost.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_gboost, open('model_gboost.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_lgb ={'num_leaves': [4,5,6],\n",
    "                              'learning_rate':[0.04, 0.05, 0.06], \n",
    "                              'n_estimators':[500,700, 900],\n",
    "                              'max_bin': [40, 50, 60], \n",
    "                              'bagging_fraction': [0.7, 0.8, 0.9],\n",
    "                              'bagging_freq': [4, 5, 6], \n",
    "                              'feature_fraction': [0.1,0.2,0.3],\n",
    "                              'feature_fraction_seed':[7,8,9], \n",
    "                              'bagging_seed': [7,8,9],\n",
    "                              'min_data_in_leaf': [5,6,7], \n",
    "                              'min_sum_hessian_in_leaf': [11]\n",
    "                            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_lgb= GridSearchCV(estimator=lgb.LGBMRegressor(objective='regression',random_state=rs_const), param_grid=param_grid_lgb,n_jobs=-1, cv=5,verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 59049 candidates, totalling 295245 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   25.9s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:   53.9s\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  1.9min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed:  4.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed:  6.2min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed:  8.1min\n",
      "[Parallel(n_jobs=-1)]: Done 3192 tasks      | elapsed: 10.3min\n",
      "[Parallel(n_jobs=-1)]: Done 4042 tasks      | elapsed: 13.1min\n",
      "[Parallel(n_jobs=-1)]: Done 4992 tasks      | elapsed: 16.2min\n",
      "[Parallel(n_jobs=-1)]: Done 6042 tasks      | elapsed: 19.8min\n",
      "[Parallel(n_jobs=-1)]: Done 7192 tasks      | elapsed: 23.7min\n",
      "[Parallel(n_jobs=-1)]: Done 8442 tasks      | elapsed: 27.8min\n",
      "[Parallel(n_jobs=-1)]: Done 9792 tasks      | elapsed: 32.3min\n",
      "[Parallel(n_jobs=-1)]: Done 11242 tasks      | elapsed: 37.3min\n",
      "[Parallel(n_jobs=-1)]: Done 12792 tasks      | elapsed: 42.2min\n",
      "[Parallel(n_jobs=-1)]: Done 14442 tasks      | elapsed: 47.5min\n",
      "[Parallel(n_jobs=-1)]: Done 16192 tasks      | elapsed: 53.4min\n",
      "[Parallel(n_jobs=-1)]: Done 18042 tasks      | elapsed: 60.6min\n",
      "[Parallel(n_jobs=-1)]: Done 19992 tasks      | elapsed: 67.9min\n",
      "[Parallel(n_jobs=-1)]: Done 22042 tasks      | elapsed: 75.6min\n",
      "[Parallel(n_jobs=-1)]: Done 24192 tasks      | elapsed: 82.3min\n",
      "[Parallel(n_jobs=-1)]: Done 26442 tasks      | elapsed: 90.6min\n",
      "[Parallel(n_jobs=-1)]: Done 28792 tasks      | elapsed: 99.4min\n",
      "[Parallel(n_jobs=-1)]: Done 31242 tasks      | elapsed: 107.9min\n",
      "[Parallel(n_jobs=-1)]: Done 33792 tasks      | elapsed: 116.2min\n",
      "[Parallel(n_jobs=-1)]: Done 36442 tasks      | elapsed: 124.0min\n",
      "[Parallel(n_jobs=-1)]: Done 39192 tasks      | elapsed: 132.3min\n",
      "[Parallel(n_jobs=-1)]: Done 42042 tasks      | elapsed: 141.2min\n",
      "[Parallel(n_jobs=-1)]: Done 44992 tasks      | elapsed: 150.0min\n",
      "[Parallel(n_jobs=-1)]: Done 48042 tasks      | elapsed: 158.7min\n",
      "[Parallel(n_jobs=-1)]: Done 51192 tasks      | elapsed: 168.2min\n",
      "[Parallel(n_jobs=-1)]: Done 54442 tasks      | elapsed: 178.3min\n",
      "[Parallel(n_jobs=-1)]: Done 57792 tasks      | elapsed: 187.8min\n",
      "[Parallel(n_jobs=-1)]: Done 61242 tasks      | elapsed: 198.1min\n",
      "[Parallel(n_jobs=-1)]: Done 64792 tasks      | elapsed: 209.1min\n",
      "[Parallel(n_jobs=-1)]: Done 68442 tasks      | elapsed: 219.5min\n",
      "[Parallel(n_jobs=-1)]: Done 72192 tasks      | elapsed: 230.6min\n",
      "[Parallel(n_jobs=-1)]: Done 76042 tasks      | elapsed: 242.5min\n",
      "[Parallel(n_jobs=-1)]: Done 79992 tasks      | elapsed: 253.7min\n",
      "[Parallel(n_jobs=-1)]: Done 84042 tasks      | elapsed: 265.8min\n",
      "[Parallel(n_jobs=-1)]: Done 88192 tasks      | elapsed: 278.4min\n",
      "[Parallel(n_jobs=-1)]: Done 92442 tasks      | elapsed: 290.5min\n",
      "[Parallel(n_jobs=-1)]: Done 96792 tasks      | elapsed: 303.7min\n",
      "[Parallel(n_jobs=-1)]: Done 101242 tasks      | elapsed: 316.8min\n",
      "[Parallel(n_jobs=-1)]: Done 105792 tasks      | elapsed: 330.6min\n",
      "[Parallel(n_jobs=-1)]: Done 110442 tasks      | elapsed: 345.1min\n",
      "[Parallel(n_jobs=-1)]: Done 115192 tasks      | elapsed: 359.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120042 tasks      | elapsed: 374.6min\n",
      "[Parallel(n_jobs=-1)]: Done 124992 tasks      | elapsed: 392.2min\n",
      "[Parallel(n_jobs=-1)]: Done 130042 tasks      | elapsed: 411.0min\n",
      "[Parallel(n_jobs=-1)]: Done 135192 tasks      | elapsed: 427.5min\n",
      "[Parallel(n_jobs=-1)]: Done 140442 tasks      | elapsed: 446.1min\n",
      "[Parallel(n_jobs=-1)]: Done 145792 tasks      | elapsed: 465.4min\n",
      "[Parallel(n_jobs=-1)]: Done 151242 tasks      | elapsed: 488.0min\n",
      "[Parallel(n_jobs=-1)]: Done 156792 tasks      | elapsed: 506.9min\n",
      "[Parallel(n_jobs=-1)]: Done 162442 tasks      | elapsed: 526.1min\n",
      "[Parallel(n_jobs=-1)]: Done 168192 tasks      | elapsed: 544.7min\n",
      "[Parallel(n_jobs=-1)]: Done 174042 tasks      | elapsed: 564.3min\n",
      "[Parallel(n_jobs=-1)]: Done 179992 tasks      | elapsed: 582.0min\n",
      "[Parallel(n_jobs=-1)]: Done 186042 tasks      | elapsed: 601.0min\n",
      "[Parallel(n_jobs=-1)]: Done 192192 tasks      | elapsed: 619.0min\n",
      "[Parallel(n_jobs=-1)]: Done 198442 tasks      | elapsed: 638.3min\n",
      "[Parallel(n_jobs=-1)]: Done 204792 tasks      | elapsed: 657.7min\n",
      "[Parallel(n_jobs=-1)]: Done 211242 tasks      | elapsed: 677.5min\n",
      "[Parallel(n_jobs=-1)]: Done 217792 tasks      | elapsed: 699.0min\n",
      "[Parallel(n_jobs=-1)]: Done 224442 tasks      | elapsed: 720.6min\n",
      "[Parallel(n_jobs=-1)]: Done 231192 tasks      | elapsed: 742.1min\n",
      "[Parallel(n_jobs=-1)]: Done 238042 tasks      | elapsed: 765.5min\n",
      "[Parallel(n_jobs=-1)]: Done 244992 tasks      | elapsed: 788.1min\n",
      "[Parallel(n_jobs=-1)]: Done 252042 tasks      | elapsed: 811.9min\n",
      "[Parallel(n_jobs=-1)]: Done 259192 tasks      | elapsed: 835.6min\n",
      "[Parallel(n_jobs=-1)]: Done 266442 tasks      | elapsed: 860.4min\n",
      "[Parallel(n_jobs=-1)]: Done 273792 tasks      | elapsed: 884.8min\n",
      "[Parallel(n_jobs=-1)]: Done 281242 tasks      | elapsed: 907.5min\n",
      "[Parallel(n_jobs=-1)]: Done 288792 tasks      | elapsed: 930.7min\n",
      "[Parallel(n_jobs=-1)]: Done 295245 out of 295245 | elapsed: 951.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
       "       importance_type='split', learning_rate=0.1, max_depth=-1,\n",
       "       min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
       "       n_estimators=100, n_jobs=-1, num_leaves=31, objective='regression',\n",
       "       random_state=80, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'num_leaves': [4, 5, 6], 'learning_rate': [0.04, 0.05, 0.06], 'n_estimators': [500, 700, 900], 'max_bin': [40, 50, 60], 'bagging_fraction': [0.7, 0.8, 0.9], 'bagging_freq': [4, 5, 6], 'feature_fraction': [0.1, 0.2, 0.3], 'feature_fraction_seed': [7, 8, 9], 'bagging_seed': [7, 8, 9], 'min_data_in_leaf': [5, 6, 7], 'min_sum_hessian_in_leaf': [11]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_lgb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate The Model And Print The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "lgb: Regression\n",
      "_______________________________________\n",
      "Best params: {'bagging_fraction': 0.9, 'bagging_freq': 4, 'bagging_seed': 9, 'feature_fraction': 0.1, 'feature_fraction_seed': 7, 'learning_rate': 0.04, 'max_bin': 40, 'min_data_in_leaf': 6, 'min_sum_hessian_in_leaf': 11, 'n_estimators': 700, 'num_leaves': 6}\n",
      "Best score : 0.896827843999088\n",
      "---------\n",
      "RMSE train: 0.08493187271043416\n",
      "RMSE test : 0.10346124046188622\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________\")\n",
    "print(\"lgb: Regression\")\n",
    "print(\"_______________________________________\")\n",
    "print('Best params: {}'.format(gridsearch_lgb.best_params_))\n",
    "print('Best score : {}'.format(gridsearch_lgb.best_score_))\n",
    "print(\"---------\")\n",
    "model_lgb = gridsearch_lgb.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_lgb.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_lgb.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(model_lgb, open('model_lgb.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. MLP Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Hyperparameter Search Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_mlp = {'alpha': [2,2.25,2.5,2.75,3,3.25,3.5,3.75,4,4.25,4.50,5.0],\n",
    "              'activation': ['tanh'],\n",
    "               'hidden_layer_sizes' : [(10,10),(10,5), (10,20),(20,10),(20,20),(20,30),(30,30),(30,20),(20,30),(40,40),(40,30),(50,50),(60,60),(70,70),(80,80),(90,90)],\n",
    "               'solver' : ['lbfgs'],\n",
    "                'learning_rate':['adaptive'],\n",
    "                'learning_rate_init':[0.003]\n",
    "               }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridsearch_mlp = GridSearchCV(MLPRegressor(random_state=rs_const), param_grid_mlp, n_jobs=-1,cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 192 candidates, totalling 960 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   50.5s\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  3.3min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed:  6.8min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 12.1min\n",
      "[Parallel(n_jobs=-1)]: Done 960 out of 960 | elapsed: 14.7min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=MLPRegressor(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "       random_state=80, shuffle=True, solver='adam', tol=0.0001,\n",
       "       validation_fraction=0.1, verbose=False, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'alpha': [2, 2.25, 2.5, 2.75, 3, 3.25, 3.5, 3.75, 4, 4.25, 4.5, 5.0], 'activation': ['tanh'], 'hidden_layer_sizes': [(10, 10), (10, 5), (10, 20), (20, 10), (20, 20), (20, 30), (30, 30), (30, 20), (20, 30), (40, 40), (40, 30), (50, 50), (60, 60), (70, 70), (80, 80), (90, 90)], 'solver': ['lbfgs'], 'learning_rate': ['adaptive'], 'learning_rate_init': [0.003]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch_mlp.fit(X_train_std,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate The Model And Print The Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________\n",
      "MLP: Regression\n",
      "_______________________________________\n",
      "Best params: {'activation': 'tanh', 'alpha': 5.0, 'hidden_layer_sizes': (20, 10), 'learning_rate': 'adaptive', 'learning_rate_init': 0.003, 'solver': 'lbfgs'}\n",
      "Best score : 0.8817854092919377\n",
      "---------\n",
      "RMSE train: 0.07873849482402347\n",
      "RMSE test : 0.1067523028132266\n"
     ]
    }
   ],
   "source": [
    "print(\"_______________________________________\")\n",
    "print(\"MLP: Regression\")\n",
    "print(\"_______________________________________\")\n",
    "print('Best params: {}'.format(gridsearch_mlp.best_params_))\n",
    "print('Best score : {}'.format(gridsearch_mlp.best_score_))\n",
    "print(\"---------\")\n",
    "model_mlp = gridsearch_mlp.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_mlp.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_mlp.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(model_mlp, open('model_mlp.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
