{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the right libraries \n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import re\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 81)\n",
      "(1459, 80)\n"
     ]
    }
   ],
   "source": [
    "house = pd.read_csv('train.csv')\n",
    "house_test = pd.read_csv('test.csv')\n",
    "\n",
    "trainSize = house.shape[0]\n",
    "house.SalePrice = house.SalePrice.apply(np.log)\n",
    "print(house.shape)\n",
    "print(house_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the Id column:\n",
    "train_id = house['Id']\n",
    "test_id  = house_test['Id']\n",
    "\n",
    "# Now drop the 'Id' column \n",
    "# since we can not use it as a feature to train our model.\n",
    "house.drop(\"Id\", axis = 1, inplace = True)\n",
    "house_test.drop(\"Id\", axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distinguish the NA and missing in train data\n",
    "miss = list(house.columns[house.isnull().sum(axis = 0) >= 1])\n",
    "miss.remove('LotFrontage')\n",
    "miss.remove('MasVnrArea')\n",
    "miss.remove('GarageYrBlt')\n",
    "miss.remove('MasVnrType')\n",
    "\n",
    "house.loc[house['MasVnrType'].isnull() == True, 'MasVnrType'] = 'None'\n",
    "house.loc[house['Electrical'].isnull() == True, 'Electrical'] = 'SBrkr'\n",
    "\n",
    "for i in range(len(miss)):\n",
    "    house.loc[house[miss[i]].isnull() == True, miss[i]] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_description.txt', 'r') as file:\n",
    "    lines_level = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = ''\n",
    "levels = {}\n",
    "level = ''\n",
    "\n",
    "for line in lines_level:\n",
    "    if (not not re.findall(': ', line)) and (not re.findall('story:', line)):\n",
    "#         features.append(re.split(':', line)[0])\n",
    "        feature = re.split(':', line)[0]\n",
    "        levels[feature] = []\n",
    "    else:\n",
    "        if line != '\\n':\n",
    "#             levels.append(re.split('\\t', line)[0].strip())\n",
    "            level = re.split('\\t', line)[0].strip()\n",
    "            if level != '': levels[feature].append(level)\n",
    "levels['Id'] = []\n",
    "levels['SalePrice'] = []\n",
    "# print(levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find ordinal and non ordinal\n",
    "with open('DataDocumentation.txt', 'r',encoding='cp1252') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSSubClass', 'MSZoning', 'Street', 'Alley', 'LandContour', 'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1', 'Exterior2', 'MasVnrType', 'Foundation', 'Heating', 'CentralAir', 'GarageType', 'MiscFeature', 'SaleType', 'SaleCondition']\n",
      "['LotShape', 'Utilities', 'LandSlope', 'OverallQual', 'OverallCond', 'ExterQual', 'ExterCond', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'HeatingQC', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence']\n"
     ]
    }
   ],
   "source": [
    "nom_lines = []\n",
    "ord_lines = []\n",
    "for line in lines:\n",
    "    if re.findall('(Nominal)', line):\n",
    "        nom_lines.append(re.sub(' ', '', re.split('\\(Nominal\\)', line)[0].strip()))\n",
    "    elif re.findall('(Ordinal)', line):\n",
    "        ord_lines.append(re.sub(' ', '', re.split('\\(Ordinal\\)', line)[0].strip()))\n",
    "print(nom_lines)\n",
    "print(ord_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_cat(col, levels, ord_lines):\n",
    "    if not not levels[col.name]: \n",
    "        if col.name in ord_lines:\n",
    "            temp = pd.Categorical(list(col.astype('str')), ordered=True, categories=levels[col.name][::-1])\n",
    "            temp.name = col.name\n",
    "            return temp\n",
    "        else:\n",
    "            temp = pd.Categorical(list(col.astype('str')), categories=levels[col.name][::-1])\n",
    "            temp.name = col.name\n",
    "            return temp\n",
    "   \n",
    "    else:\n",
    "        return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in house:\n",
    "    house[col] = my_cat(house[col], levels, ord_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "miss = list(house_test.columns[house_test.isnull().sum(axis = 0) >= 1])\n",
    "miss.remove('LotFrontage')\n",
    "miss.remove('MasVnrArea')\n",
    "miss.remove('GarageYrBlt')\n",
    "miss.remove('TotalBsmtSF')\n",
    "miss.remove('BsmtHalfBath')\n",
    "miss.remove('BsmtFullBath')\n",
    "miss.remove('GarageCars')\n",
    "miss.remove('GarageArea')\n",
    "miss.remove('BsmtFinSF1')\n",
    "miss.remove('BsmtFinSF2')\n",
    "miss.remove('BsmtUnfSF')\n",
    "\n",
    "house_test.loc[house_test['MasVnrType'].isnull() == True, 'MasVnrType'] = 'CBlock'\n",
    "house_test.loc[house_test['SaleType'].isnull() == True, 'SaleType'] = 'Oth'\n",
    "house_test.loc[house_test['Functional'].isnull() == True, 'Functional'] = 'Sal'\n",
    "house_test.loc[house_test['MSZoning'].isnull() == True, 'MSZoning'] = 'A'\n",
    "house_test.loc[house_test['Exterior1st'].isnull() == True, 'Exterior1st'] = 'WdShing'\n",
    "house_test.loc[house_test['Exterior2nd'].isnull() == True, 'Exterior2nd'] = 'Wd Shng'\n",
    "\n",
    "for i in range(len(miss)):\n",
    "    house_test.loc[house_test[miss[i]].isnull() == True, miss[i]] = 'NA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in house_test:\n",
    "    house_test[col] = my_cat(house_test[col], levels, ord_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
      "['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['NA', 'Unf', 'RFn', 'Fin']\n",
      "['NA', 'Po', 'Fa', 'TA', 'Gd', 'Ex']\n",
      "['Po', 'Fa', 'TA', 'Gd', 'Ex']\n"
     ]
    }
   ],
   "source": [
    "print(levels['OverallQual'][::-1])\n",
    "print(levels['ExterQual'][::-1])\n",
    "print(levels['BsmtQual'][::-1])\n",
    "print(levels['KitchenQual'][::-1])\n",
    "print(levels['GarageFinish'][::-1])\n",
    "print(levels['FireplaceQu'][::-1])\n",
    "print(levels['HeatingQC'][::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OrdinalsToNumerics(all_data):    \n",
    "    all_data['ExterQual'] = all_data['ExterQual'].map(lambda x: {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}.get(x, 0))\n",
    "    all_data['BsmtQual'] = all_data['BsmtQual'].map(lambda x: {'NA':1,'Po':2, 'Fa':3, 'TA':4, 'Gd':5, 'Ex':6}.get(x, 0))\n",
    "    all_data['KitchenQual'] = all_data['KitchenQual'].map(lambda x: {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}.get(x, 0))\n",
    "    all_data['GarageFinish'] = all_data['GarageFinish'].map(lambda x: {'NA':1, 'Unf':2, 'RFn':3, 'Fin':4}.get(x, 0))\n",
    "    all_data['FireplaceQu'] = all_data['FireplaceQu'].map(lambda x: {'NA':1,'Po':2, 'Fa':3, 'TA':4, 'Gd':5, 'Ex':6}.get(x, 0))\n",
    "    all_data['HeatingQC'] = all_data['HeatingQC'].map(lambda x: {'Po':1, 'Fa':2, 'TA':3, 'Gd':4, 'Ex':5}.get(x, 0))\n",
    "\n",
    "    all_data['OverallQual'] = pd.to_numeric(all_data['OverallQual'])\n",
    "    all_data['ExterQual'] = pd.to_numeric(all_data['ExterQual'])\n",
    "    all_data['BsmtQual'] = pd.to_numeric(all_data['BsmtQual'])\n",
    "    all_data['KitchenQual'] = pd.to_numeric(all_data['KitchenQual'])\n",
    "    all_data['GarageFinish'] = pd.to_numeric(all_data['GarageFinish'])\n",
    "    all_data['FireplaceQu'] = pd.to_numeric(all_data['FireplaceQu'])\n",
    "    all_data['HeatingQC'] = pd.to_numeric(all_data['HeatingQC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea taken from this script: https://www.kaggle.com/serigne/stacked-regressions-top-4-on-leaderboard\n",
    "\n",
    "\n",
    "def FeatureEngineering(all_data):\n",
    "    # Adding total sqfootage feature \n",
    "    all_data['GarageYrBlt'][all_data['GarageYrBlt'].isnull()] = all_data['YearBuilt'][all_data['GarageYrBlt'].isnull()]\n",
    "    all_data['GarageYrBlt'] = all_data['GarageYrBlt'] - all_data['YearBuilt']\n",
    "\n",
    "    #all_data['YrSold'] = all_data['YrSold'] - all_data['YearBuilt']\n",
    "    \n",
    "    all_data['MoSold'] = pd.Categorical(list(all_data['MoSold'].astype('str')))\n",
    "    \n",
    "    all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
    "\n",
    "    # GarageYrBlt, GarageArea and GarageCars : Replacing missing data with 0 (Since No garage = no cars in such garage.)\n",
    "    for col in ('GarageArea', 'GarageCars'):\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "    # BsmtFinSF1, BsmtFinSF2, BsmtUnfSF, TotalBsmtSF, BsmtFullBath and BsmtHalfBath : missing values are likely zero for having no basement\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        all_data[col] = all_data[col].fillna(0)\n",
    "\n",
    "    # LotFrontage : Since the area of each street connected to the house property most likely have a similar \n",
    "    # area to other houses in its neighborhood , we can fill in missing values by the median LotFrontage of the neighborhood.\n",
    "    # Group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\n",
    "    all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(lambda x: x.fillna(x.median()))\n",
    "    \n",
    "    all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
    "    \n",
    "    # Utilities : For this categorical feature all records are \"AllPub\", except for one \"NoSeWa\" and 2 NA . Since the house with 'NoSewa' is in the training set, this feature won't help in predictive modelling. We can then safely remove it.\n",
    "    all_data = all_data.drop(['Utilities'], axis=1)\n",
    "\n",
    "drop_cols1 = [\"Alley\", \"ExterCond\", \"BsmtFinSF2\", \"Heating\", \"Electrical\",\\\n",
    "              \"BsmtHalfBath\", \"PavedDrive\", \"Fence\", \"MiscFeature\", \"MoSold\"]\n",
    "\n",
    "drop_cols2 = [\"BsmtFinType2\", \"LandContour\", \"EnclosedPorch\",\\\n",
    "              \"SaleType\", \"Functional\", \"LotConfig\",\\\n",
    "              \"ScreenPorch\", \"YrSold\", \"LandSlope\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DropColumns(all_data):\n",
    "    for col in [*drop_cols1, *drop_cols2]:\n",
    "        all_data.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = house.SalePrice\n",
    "house.drop('SalePrice', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "OrdinalsToNumerics(house)\n",
    "OrdinalsToNumerics(house_test)\n",
    "\n",
    "FeatureEngineering(house)\n",
    "FeatureEngineering(house_test)\n",
    "\n",
    "DropColumns(house)\n",
    "DropColumns(house_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.concat([house, house_test], ignore_index = True)\n",
    "all_data = pd.get_dummies(all_data, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 219)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = all_data.iloc[:trainSize,:]\n",
    "train_clean = train_clean.assign(SalePrice = price.values)\n",
    "train_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1460"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 218)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_clean = all_data.iloc[trainSize:, :]\n",
    "test_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import sklearn.model_selection as ms\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor #as gbr as rfr\n",
    "from mlxtend.regressor import StackingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "def rmse(y, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs_const = 80 #to make sure that we apply the same one value for all model tuning process\n",
    "test_ratio_const = 0.2 \n",
    "\n",
    "train_data   = train_clean.drop('SalePrice', axis=1)\n",
    "train_target = train_clean[['SalePrice']]\n",
    "test_data    = test_clean\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data, train_target,\\\n",
    "                                                    test_size=test_ratio_const, random_state=rs_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype uint8, int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train_std = scaler.transform(X_train)\n",
    "X_test_std  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lr = linear_model.LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE train: 0.10262489450225752\n",
      "RMSE test : 0.1273096943564471\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE train: {}\".format(rmse(y_train, model_lr.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_lr.predict(X_test))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Kernel Ridge Regression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = [{'alpha': np.logspace(-4, 4, 20)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling  the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=linear_model.Ridge(random_state=rs_const), param_grid=grid_param, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=80, solver='auto', tol=0.001),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'alpha': array([1.00000e-04, 2.63665e-04, 6.95193e-04, 1.83298e-03, 4.83293e-03,\n",
       "       1.27427e-02, 3.35982e-02, 8.85867e-02, 2.33572e-01, 6.15848e-01,\n",
       "       1.62378e+00, 4.28133e+00, 1.12884e+01, 2.97635e+01, 7.84760e+01,\n",
       "       2.06914e+02, 5.45559e+02, 1.43845e+03, 3.79269e+03, 1.00000e+04])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 545.5594781168514}\n",
      "Best score : 0.862816990220294\n",
      "RMSE train: 0.11500081056347171\n",
      "RMSE test : 0.09967169272824544\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "\n",
    "\n",
    "model_rd = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_rd.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_rd.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Lasso Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = [{'alpha': np.logspace(-3, 4, 20)}] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=linear_model.Lasso(random_state=rs_const, normalize=False), param_grid=grid_param, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=80,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'alpha': array([1.00000e-03, 2.33572e-03, 5.45559e-03, 1.27427e-02, 2.97635e-02,\n",
       "       6.95193e-02, 1.62378e-01, 3.79269e-01, 8.85867e-01, 2.06914e+00,\n",
       "       4.83293e+00, 1.12884e+01, 2.63665e+01, 6.15848e+01, 1.43845e+02,\n",
       "       3.35982e+02, 7.84760e+02, 1.83298e+03, 4.28133e+03, 1.00000e+04])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.00545559478116852}\n",
      "Best score : 0.8564711534949876\n",
      "RMSE train: 0.11402145996484198\n",
      "RMSE test : 0.09659128729814824\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "\n",
    "model = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Elastic Net Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model grid parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = [{'alpha': np.logspace(-2, 4, 20), 'l1_ratio': np.linspace(0.015, 1, 20)}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(estimator=linear_model.ElasticNet(random_state=rs_const), param_grid=grid_param, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.5,\n",
       "      max_iter=1000, normalize=False, positive=False, precompute=False,\n",
       "      random_state=80, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid=[{'alpha': array([1.00000e-02, 2.06914e-02, 4.28133e-02, 8.85867e-02, 1.83298e-01,\n",
       "       3.79269e-01, 7.84760e-01, 1.62378e+00, 3.35982e+00, 6.95193e+00,\n",
       "       1.43845e+01, 2.97635e+01, 6.15848e+01, 1.27427e+02, 2.63665e+02,\n",
       "       5.45559e+02, 1.12884e+03, 2.33572e+03, 4.83293e+03, 1.0... 0.53342, 0.58526, 0.63711, 0.68895,\n",
       "       0.74079, 0.79263, 0.84447, 0.89632, 0.94816, 1.     ])}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'alpha': 0.18329807108324356, 'l1_ratio': 0.015}\n",
      "Best score : 0.8652189389746141\n",
      "RMSE train: 0.1127655445071562\n",
      "RMSE test : 0.0955844475998484\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "\n",
    "model_en = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_en.predict(X_train_std))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_en.predict(X_test_std))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setting up the model hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    " 'max_depth':[4,6,8],\n",
    " 'n_estimators':[1000,1500,2000,2500,3000],\n",
    "'min_child_weight':range(1,3),\n",
    "'learning_rate':[.1,.01,.001],\n",
    "'colsample_bytree':[.8,.9,1]\n",
    ",'gamma':[0,1]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buidling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with the parameter nthread we specify XGBoost for parallelisation \n",
    "cvx = xgb.XGBRegressor(random_state=rs_const, objective= \"reg:linear\",nthread=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs=GridSearchCV(estimator=cvx,param_grid=params,n_jobs=-1,cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating the model and printing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 540 candidates, totalling 2700 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:  8.8min\n",
      "[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed: 40.2min\n",
      "[Parallel(n_jobs=-1)]: Done 442 tasks      | elapsed: 114.1min\n",
      "[Parallel(n_jobs=-1)]: Done 792 tasks      | elapsed: 223.2min\n",
      "[Parallel(n_jobs=-1)]: Done 1242 tasks      | elapsed: 341.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1792 tasks      | elapsed: 525.9min\n",
      "[Parallel(n_jobs=-1)]: Done 2442 tasks      | elapsed: 700.5min\n",
      "[Parallel(n_jobs=-1)]: Done 2700 out of 2700 | elapsed: 771.6min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=-1, objective='reg:linear', random_state=80,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': [4, 6, 8], 'n_estimators': [1000, 1500, 2000, 2500, 3000], 'min_child_weight': range(1, 3), 'learning_rate': [0.1, 0.01, 0.001], 'colsample_bytree': [0.8, 0.9, 1], 'gamma': [0, 1]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params: {'colsample_bytree': 0.8, 'gamma': 0, 'learning_rate': 0.01, 'max_depth': 4, 'min_child_weight': 2, 'n_estimators': 2000}\n",
      "Best score : 0.8945528519113021\n",
      "RMSE train: 0.056005723679234946\n",
      "RMSE test : 0.09890042608186725\n"
     ]
    }
   ],
   "source": [
    "print('Best params: {}'.format(gs.best_params_))\n",
    "print('Best score : {}'.format(gs.best_score_))\n",
    "\n",
    "model_gbt = gs.best_estimator_\n",
    "print(\"RMSE train: {}\".format(rmse(y_train, model_gbt.predict(X_train))))\n",
    "print(\"RMSE test : {}\".format(rmse(y_test,  model_gbt.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
 2+2;
